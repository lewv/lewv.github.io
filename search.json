[
  {
    "objectID": "Presenting.html#tonights-goals",
    "href": "Presenting.html#tonights-goals",
    "title": "Presenting @ DataFest",
    "section": "Tonight’s goals",
    "text": "Tonight’s goals\n\nTo offer guidance and\nTo encourage you to make your discoveries accessible and understandable\n\nTo the entire DataFest audience (from N00b to expert)\n\nyet uphold the credibility and accuracy of your work."
  },
  {
    "objectID": "Presenting.html#know-the-level-of-understanding-of-your-audience.",
    "href": "Presenting.html#know-the-level-of-understanding-of-your-audience.",
    "title": "Presenting @ DataFest",
    "section": "1. Know the level of understanding of your audience.",
    "text": "1. Know the level of understanding of your audience.\n\nAfter 40+ hours\n\nYour peers will be experts BUT they do not have judging power.\n\nDo not worry about peers judging you when you are presenting.\n\nThe judges have judging power. Two flavors:\n\nThe stakeholders e.g., 2015 Edmunds.com managers/lawyers judging\nThe professional Statisticians, Data Scientists, etc."
  },
  {
    "objectID": "Presenting.html#tailor-your-presentation.",
    "href": "Presenting.html#tailor-your-presentation.",
    "title": "Presenting @ DataFest",
    "section": "2. Tailor your presentation.",
    "text": "2. Tailor your presentation.\n\nExample. Edmunds.com DataFest 2015.\n\nTwo teams vying for the top prize (Best Insight).\n\nTeam One: a sophisticated analysis, machine learning techniques involving consumer choice modeling. Their team leader had wheeled in a modified server (this is 2015) with 32GB of memory to compete at DataFest."
  },
  {
    "objectID": "Presenting.html#tailor-your-presentation.-contd",
    "href": "Presenting.html#tailor-your-presentation.-contd",
    "title": "Presenting @ DataFest",
    "section": "2. Tailor your presentation. (cont’d)",
    "text": "2. Tailor your presentation. (cont’d)\n\nTeam Two: a basic analysis, their presentation slide just had a few numbers from tables, a test, and pretty graphics.\nWho do you think won?\n\nTeam Two.\n\nThe Team One cried foul and said they were “ripped off”.\nThe judging panel responded that the data provider “didn’t understand Team One’s analysis and as result, could not use the recommendation”"
  },
  {
    "objectID": "Presenting.html#kiss",
    "href": "Presenting.html#kiss",
    "title": "Presenting @ DataFest",
    "section": "3. KISS",
    "text": "3. KISS\n\nTeam One opened with “We utilized walking-forward cross-validation” (AKA time series cross validation or time series split)\nTMI\nIt might be wiser to mention it only when the experts ask if you performed any cross-validation.\nThink about it"
  },
  {
    "objectID": "Presenting.html#kiss-contd",
    "href": "Presenting.html#kiss-contd",
    "title": "Presenting @ DataFest",
    "section": "3. KISS! (cont’d)",
    "text": "3. KISS! (cont’d)\n\nIf you are going to step up there and begin talking about performing a rolling time series split of the data, you may be compressing your audience from a few hundred to a few dozen people in that room.\n\nIt’s OK, but if you are going to do that, your compressed audience MUST INCLUDE the data provider.\n\nIf the data provider understands your talk, guess what…\n\nthe experts will too.\n\nGive enough detail to establish credibility with the experts but avoid overwhelming the non-experts."
  },
  {
    "objectID": "Presenting.html#where-to-start-suggestions",
    "href": "Presenting.html#where-to-start-suggestions",
    "title": "Presenting @ DataFest",
    "section": "4. Where to Start (suggestions)",
    "text": "4. Where to Start (suggestions)\n\nSuggestion: clear statements of\n\nWhat your analysis aimed to achieve AND\nWhy your analysis matters\n\nDo this to engage your audience from the beginning."
  },
  {
    "objectID": "Presenting.html#suggestion-a-picture-is-worth-1000-words.",
    "href": "Presenting.html#suggestion-a-picture-is-worth-1000-words.",
    "title": "Presenting @ DataFest",
    "section": "(suggestion) A PICTURE IS WORTH 1000 words.",
    "text": "(suggestion) A PICTURE IS WORTH 1000 words.\n\nUse charts, graphs, and/or infographics to make complex data more understandable.\nVisuals should be clear, labeled correctly, and uncomplicated.\nSlides from the 2017 winner (Best Insight, the top prize at the time)"
  },
  {
    "objectID": "Presenting.html#winner",
    "href": "Presenting.html#winner",
    "title": "Presenting @ DataFest",
    "section": "2017 Winner",
    "text": "2017 Winner"
  },
  {
    "objectID": "Presenting.html#suggestion-whats-your-story",
    "href": "Presenting.html#suggestion-whats-your-story",
    "title": "Presenting @ DataFest",
    "section": "(Suggestion) What’s Your Story?",
    "text": "(Suggestion) What’s Your Story?\n\n\n\nIntroduce the key elements or variables of your analysis\nDiscuss your solution with a logical flow\n\nfrom your solution/idea\nto results and impact"
  },
  {
    "objectID": "Presenting.html#whats-your-story-contd",
    "href": "Presenting.html#whats-your-story-contd",
    "title": "Presenting @ DataFest",
    "section": "What’s Your Story? (Cont’d)",
    "text": "What’s Your Story? (Cont’d)\n\n\n\n\n\n\nYour “story” should be interesting to the stakeholder.\nYour findings should be relatable and understandable."
  },
  {
    "objectID": "Presenting.html#finish-well",
    "href": "Presenting.html#finish-well",
    "title": "Presenting @ DataFest",
    "section": "5. Finish Well!",
    "text": "5. Finish Well!\n\nSummarize/Emphasize the most important results of your analysis\nDo make it clear to others why your findings matter\nExplain how your findings fit the needs of the data provider."
  },
  {
    "objectID": "Presenting.html#finish-well---2017-winner",
    "href": "Presenting.html#finish-well---2017-winner",
    "title": "Presenting @ DataFest",
    "section": "Finish Well - 2017 Winner",
    "text": "Finish Well - 2017 Winner"
  },
  {
    "objectID": "Presenting.html#be-prepared-for-questions",
    "href": "Presenting.html#be-prepared-for-questions",
    "title": "Presenting @ DataFest",
    "section": "6. Be Prepared for Questions",
    "text": "6. Be Prepared for Questions\n\nTechnical questions from stats & data science experts\n\nGeneral questions from the non-stats & data science experts\n\nAsk: yourselves, your friends, your competitors, the mentors on the floor – Ask them to ask you Questions!"
  },
  {
    "objectID": "Presenting.html#try-to-practice-your-presentation",
    "href": "Presenting.html#try-to-practice-your-presentation",
    "title": "Presenting @ DataFest",
    "section": "7. (Try to) Practice your Presentation",
    "text": "7. (Try to) Practice your Presentation\n\nClarity\nTiming\n& build confidence in your delivery. (2/9/2024)"
  },
  {
    "objectID": "Presenting.html#in-the-end-in-whatever-you-do-have-fun-doing-it.",
    "href": "Presenting.html#in-the-end-in-whatever-you-do-have-fun-doing-it.",
    "title": "Presenting @ DataFest",
    "section": "8. In the end, in whatever you do, have fun doing it.",
    "text": "8. In the end, in whatever you do, have fun doing it.\n\nYou will only be this young, this strong, in this place and in this time once.\n\nIf you are not enjoying your time, then you are truly wasting your time."
  },
  {
    "objectID": "ForLACSD.html#todays-goals",
    "href": "ForLACSD.html#todays-goals",
    "title": "LACSD presentation",
    "section": "Today’s goals",
    "text": "Today’s goals\nTo help you answer:\n\nWhat is & Why the Normal Distribution?\n\nWhat is an outlier? (Why should you care?)\n\nWhy Dixon? Why Rosner?\n\nWhat is alpha \\(\\alpha\\)? Why \\(\\alpha\\)= 0.05? Why \\(\\alpha\\) = 0.01?\n\nWhat do you do when data is non-normal?"
  },
  {
    "objectID": "ForLACSD.html#section",
    "href": "ForLACSD.html#section",
    "title": "LACSD presentation",
    "section": "",
    "text": "What is & Why the normal distribution?\nGalton Board\n(https://www.mathsisfun.com/data/quincunx.html)\n\n“Normal” because the people who worked with data at that time thought all distributions had this bell shape. Many do, but not all.\nThe importance of the normal arises from the fact that many important distributions (e.g., errors in measurement, anthropometric measurements) are normally distributed\nThe Galton board is a demonstration of how the normal distribution is the result of many “binary” (0,1) decisions"
  },
  {
    "objectID": "ForLACSD.html#section-1",
    "href": "ForLACSD.html#section-1",
    "title": "LACSD presentation",
    "section": "",
    "text": "What is & Why the normal distribution? (cont’d)\n\nA distribution is a pattern\n\nSo when we say something is “normally distributed,” we mean:\n\nMost values are average or close to average.\n\nVery high or very low values are rare.\n\nThe pattern of values forms a bell shape when graphed."
  },
  {
    "objectID": "ForLACSD.html#section-2",
    "href": "ForLACSD.html#section-2",
    "title": "LACSD presentation",
    "section": "",
    "text": "What is an outlier & Why should you care?\n\nIn Statistics, an outlier is an observation (measurement) that is significantly different from other observations (measurements) in a dataset.\n\nOutliers are one of those rare higher or lower data points.\n\nOutliers may indicate natural variability, error in measurement, or something new.\n\nOutliers are not “bad” or “evil” but…\nOutliers can unduly influence the results of statistical analyses which may lead to misleading interpretations and bad decisions."
  },
  {
    "objectID": "ForLACSD.html#why-dixon",
    "href": "ForLACSD.html#why-dixon",
    "title": "LACSD presentation",
    "section": "Why Dixon?",
    "text": "Why Dixon?\n\nDixon’s Q test is used to identify an outlier.\n\nDixon’s test assumes the data originates from a normal distribution.\n\nThis test can only identify a single outlier in a data set.\n\nFor small samples (size 3 to about 30), this is the best performing test."
  },
  {
    "objectID": "ForLACSD.html#why-rosner",
    "href": "ForLACSD.html#why-rosner",
    "title": "LACSD presentation",
    "section": "Why Rosner?",
    "text": "Why Rosner?\n\nRosner ESD test can identify up to 10 outliers in set of measurements and has been shown to be very accurate for n ≥ 25.\nRosner’s test does not require a user to know how many outliers there are beforehand.\n\nRosner also assumes the data originates from a normal distribution.\n\nRosner’s test can detect outliers even when tests like Dixon (single outlier) cannot because multiple outliers could mask each other."
  },
  {
    "objectID": "ForLACSD.html#what-is-alpha-alpha-why-alpha-0.05",
    "href": "ForLACSD.html#what-is-alpha-alpha-why-alpha-0.05",
    "title": "LACSD presentation",
    "section": "What is alpha \\(\\alpha\\)? Why \\(\\alpha\\)= 0.05?",
    "text": "What is alpha \\(\\alpha\\)? Why \\(\\alpha\\)= 0.05?\n\nLet’s play a game. I will lay down the rules/features of this game.\nSuppose I am trying to figure out if any of you have superpowers.\nThere are two kinds of candies in this jar.\nIf you can guess the color correctly in order for 9 or more (either 9 or all 10) of the first 10 I pull out, I declare that you have superpowers."
  },
  {
    "objectID": "ForLACSD.html#section-3",
    "href": "ForLACSD.html#section-3",
    "title": "LACSD presentation",
    "section": "",
    "text": "What is alpha \\(\\alpha\\)? Why \\(\\alpha\\)= 0.05? (cont’d)\n\nWhy 9 or all 10? Why not another value, like 7?\nDemanding 9 or all 10 is similar to setting alpha \\(\\alpha\\) in statistics. Alpha is a threshold or “line in the sand” that indicates how extreme a result needs to be before we think something other than luck alone is at work.\n\nWe typically use an Alpha level of 0.05 (it’s OK to think 5%)"
  },
  {
    "objectID": "ForLACSD.html#section-4",
    "href": "ForLACSD.html#section-4",
    "title": "LACSD presentation",
    "section": "",
    "text": "Normal Distribution with (two-sided) Alpha = 0.05 Shaded\nThe total of both red areas is 0.05 (0.025 under each tail)"
  },
  {
    "objectID": "ForLACSD.html#section-5",
    "href": "ForLACSD.html#section-5",
    "title": "LACSD presentation",
    "section": "",
    "text": "What is alpha \\(\\alpha\\)? Why \\(\\alpha\\)= 0.05? (cont’d)\nAny discussion of alpha should also include a discussion of the P-value\n\nSuppose you make your guess, and it turns out you guessed 9 out of the 10 candies correctly.\n\nMathematically, that is a probability of 0.021 or 2.1%\nWe will label the 0.021 as a “P-value” and it is the realization of the guess.\n\nGiven the agreed upon rule (9 or 10), I declare that you have superpowers."
  },
  {
    "objectID": "ForLACSD.html#section-6",
    "href": "ForLACSD.html#section-6",
    "title": "LACSD presentation",
    "section": "",
    "text": "Normal Distribution with Alpha = 0.05 Shaded and p-value of 0.021 marked"
  },
  {
    "objectID": "ForLACSD.html#why-alpha-0.05-why-not-alpha-0.01",
    "href": "ForLACSD.html#why-alpha-0.05-why-not-alpha-0.01",
    "title": "LACSD presentation",
    "section": "Why \\(\\alpha\\)= 0.05? Why not \\(\\alpha\\) = 0.01?",
    "text": "Why \\(\\alpha\\)= 0.05? Why not \\(\\alpha\\) = 0.01?\n\nIn some disciplines (e.g., social sciences), researchers are willing to set alpha to 0.10\n\nIn most disciplines, researchers set it to 0.05\n\nIn still others (e.g., engineering, medicine) it is set even smaller, like 0.01, it’s like making the rule stricter/tougher.\nIf I had said “you need to get 10/10 correct” that would be setting alpha to 0.001 if only 8/10, it’s closer to 0.10"
  },
  {
    "objectID": "ForLACSD.html#section-7",
    "href": "ForLACSD.html#section-7",
    "title": "LACSD presentation",
    "section": "",
    "text": "Why \\(\\alpha\\)= 0.05? Why not \\(\\alpha\\) = 0.01? (cont’d)\n\nWhy tougher?\n\nWe want to be absolutely certain before declaring someone has evidence of superpower\nReduces the chance of falsely declaring “superpower” for what might only be a lucky guess\n\n\nIn practice, smaller alpha is used in\n\nhigh stakes situations (e.g., designing airplane wings) or\na desire for stronger evidence"
  },
  {
    "objectID": "ForLACSD.html#section-8",
    "href": "ForLACSD.html#section-8",
    "title": "LACSD presentation",
    "section": "",
    "text": "Choosing an alpha of 0.01 over 0.05 (in sum)\n\nThis is like tightening the rules of evidence to insure only the most extreme are declared to have superpowers.\n\nSimilar to saying, “I want to be certain before I declare something statistically significant”\n\n(an outlier in your case, people with superpowers in mine)\n\n\nThis is a reasonable approach when the risk involved is high or when we simply desire to minimize the chance of being wrong.\n\nDownside, choosing a small alpha might make the test too tough."
  },
  {
    "objectID": "ForLACSD.html#what-can-you-do-when-data-is-non-normal",
    "href": "ForLACSD.html#what-can-you-do-when-data-is-non-normal",
    "title": "LACSD presentation",
    "section": "What can you do when data is non-normal?",
    "text": "What can you do when data is non-normal?\n\nFirst, we suggest using graphical methods to check for outliers\n\nThen test for normality (Shapiro-Wilk, used for samples from size 3 to 5000)\n\nIf not normal, the data could be transformed (e.g., log, square root, exponential) to be normal\nAlternate solution - move to a non-parametric method (e.g., values beyond the 75th percentile + 1.5xIQR as an outlier rule)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Presentation for LACSD\nNormal Lesson\nR Refresher\nEDA\nDataFest Presentation"
  },
  {
    "objectID": "RRefresher.html",
    "href": "RRefresher.html",
    "title": "R Refresher",
    "section": "",
    "text": "This is an R Refresher adapted from Weisberg (2014) We will use packages ggplot2, knitr, dplyr and tidyr. We will use packages ggplot2, knitr, dplyr and tidyr. Also data from the palmerpenguins library."
  },
  {
    "objectID": "RRefresher.html#dim",
    "href": "RRefresher.html#dim",
    "title": "R Refresher",
    "section": "dim()",
    "text": "dim()\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "RRefresher.html#head",
    "href": "RRefresher.html#head",
    "title": "R Refresher",
    "section": "head()",
    "text": "head()\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "RRefresher.html#summary",
    "href": "RRefresher.html#summary",
    "title": "R Refresher",
    "section": "summary()",
    "text": "summary()\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSummary is being abused here. While it is fast and gives us the count of NA (missing), do consider that rounding error could occur for the summary statistics. Functions for computing stats like mean( ) can be found elsewhere:"
  },
  {
    "objectID": "RRefresher.html#descriptive-basics",
    "href": "RRefresher.html#descriptive-basics",
    "title": "R Refresher",
    "section": "descriptive basics",
    "text": "descriptive basics\nChallenge (and working with webR), in teams, please compute the following for the variable birth_year in the starwars data:\n\nmean,\nsd,\nfive number summary,\ndeciles,\nthe number of missing values\nand a count (number) of unique birth years\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "RRefresher.html#conditioninggrouping",
    "href": "RRefresher.html#conditioninggrouping",
    "title": "R Refresher",
    "section": "conditioning/grouping",
    "text": "conditioning/grouping\nWe will use more of this later in the course, but for now, you should possess these fundamental data handling skills:\n\nin base R\nWe could use some basic character manipulation to make the result a little more compact. Here’s the issue:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe variable hair_color is a little too granular, let’s propose a simple fix, just keep first mention of hair color:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNow let’s examine mass (weight) by hair_color and gender in base R:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nusing dplyr with a little tidyr\nThis is a preferred alternative to the base R solution because (1) it has more options and (2) you don’t lose as much information. First some data preparation, similar to the base R solution\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIf we were to stop after the summarize() below we would have a “long”/“tall” result suitable for data visualization and other functions, but it’s a little difficult to make comparisons as tabled results:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nBy using .groups = “drop” and a pivot_wider() (from tidyr) we arrive at a comparable outcome, notice the missing categories:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe will delve into more data handling in the future."
  },
  {
    "objectID": "RRefresher.html#locally",
    "href": "RRefresher.html#locally",
    "title": "R Refresher",
    "section": "locally",
    "text": "locally\nThis is the general format for reading data in base R (won’t run on this website, you’ll need to try it in R on your own computer)\nmy_data0 &lt;- read.table(\"filename\", header=TRUE,\nna.strings=\"NA\", sep = \"\")\nThere are modifications to this basic code, for example, read.csv() is just a alias of read.table() with sep = “,” as a default. We can use it in concert with file.choose() to allow you to select files from your local drive (won’t work here, just an example)\nmy_data1 &lt;- read.csv(file.choose(), header=TRUE,\nna.strings=\"NA\")"
  },
  {
    "objectID": "RRefresher.html#remotely",
    "href": "RRefresher.html#remotely",
    "title": "R Refresher",
    "section": "remotely",
    "text": "remotely\nWe can also read data from a website, note the use of read.table() with sep = “,”:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAnother good first step involves examining the structure of the object:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis will help identify numeric and non-numeric data.\nWe could load an additional package, readr, to allow us to read additional data formats such as Excel files (this is something you can do in section or in an assignment)"
  },
  {
    "objectID": "RRefresher.html#examples",
    "href": "RRefresher.html#examples",
    "title": "R Refresher",
    "section": "Examples",
    "text": "Examples\n\nnormal\nThe normal distribution’s root is “norm”. The function pnorm() takes a quantile and returns a probability of observing a value less than or equal to 1.96 in a standard normal distribution:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can change the pnorm defaults to accommodate a different situation, here, SAT scores combined math/verbal:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nqnorm() answers the question - given a probability what is the value of the associated quantile?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\ndnorm() - returns the height of the probability density function at points specified by the programmer. In the normal distribution, points farther from the mean have lower density\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nt\nThere are other distributions with different root names, but the same four letter identifier holds\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nchi-square\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nan additional density example and our bridge to visualization\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nTest yourself/your team\nPlease try generating values from another distribution (e.g., F, Poisson), you can find a longer list of distributions here: https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Distributions.html\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "RRefresher.html#saving-graphics",
    "href": "RRefresher.html#saving-graphics",
    "title": "R Refresher",
    "section": "saving graphics",
    "text": "saving graphics\nWe can output graphics by using the GUI or directly in our code (will only run locally):\npdf(\"myhist.pdf\", height=5, width=5)\nhist(rnorm(100))\ndev.off()"
  },
  {
    "objectID": "RRefresher.html#plot-in-base-r",
    "href": "RRefresher.html#plot-in-base-r",
    "title": "R Refresher",
    "section": "plot() in base R",
    "text": "plot() in base R\nBase R’s plot() function is a reasonable starting point and convenient:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "RRefresher.html#ggplot",
    "href": "RRefresher.html#ggplot",
    "title": "R Refresher",
    "section": "ggplot( )",
    "text": "ggplot( )\nWe have more data visualization power with ggplot. We could add straight lines (AKA fit linear models) for each species and for overall\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "RRefresher.html#plot-within-a-for-loop",
    "href": "RRefresher.html#plot-within-a-for-loop",
    "title": "R Refresher",
    "section": "plot() within a for loop",
    "text": "plot() within a for loop\nAnother example, first using base R to plot 4 graphs in a single window:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "RRefresher.html#tidyverse-style",
    "href": "RRefresher.html#tidyverse-style",
    "title": "R Refresher",
    "section": "Tidyverse style",
    "text": "Tidyverse style\nWe can do the same with ggplot, but it requires more data handling\nFirst, pivot the data from wide to long/tall:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAlways check your results:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nggplot will be much happier with “long” (AKA “tall” maybe also “stacked”)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can calculate the correlations for each set, the group_by() function combined with summarize in dplyr is very useful for that.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "RRefresher.html#five-minute-ggplot-refresher",
    "href": "RRefresher.html#five-minute-ggplot-refresher",
    "title": "R Refresher",
    "section": "Five minute ggplot refresher",
    "text": "Five minute ggplot refresher\nIf there is only one package you need in R, it’s ggplot. It’s simple and logical and flows with data beautifully. We can use penguins\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nggplot needs to know what data you plan to use and it needs to have an aesthetic (aes) specified.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNo error, but no graphic. All we have done is specified the data and given ggplot a sense of how the graphic should appear (x, y, color) as it relates to the features.\nThe “+” separates “layers”. Think of ggplot as like making a cake, you lay down the foundation and then you start decorating. Next up, the geom_ which tell ggplot how the features should be plotted.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThat is just about it. I do recommend you learn how to “facet” (condition) the plots:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nread “as a function of island”, if you wanted island on the rows, move to facet_grid()\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\na better use of facet_grid\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe remaining functions deal with appearance such as labels, legends and maybe adding additional geoms:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA",
    "section": "",
    "text": "EDA (Exploratory data analysis) involves the use of graphics, summaries and transformations to better understand the data and answer our questions.\nExploratory methods, make few assumptions about the distributional shape of the data.\nOur results can help us refine our questions or develop new ones.\n\nHere’s what Wickham says in “R for Data Science”: (page 82)\n\nYour goal during EDA is to develop an understanding of your data. The easiest way to do this is to use questions as tools to guide your investigation. When you ask a question, the question focuses your attention on a specific part of your dataset and helps you decide which graphs, models, or transformations to make.\n\nThere are no “real” rules here, but the data I’m using today comes from a competition, so obviously winning was (the competition is closed) the goal. But to win, it was important to focus on two things\n\nVariation\nCovariation\n\n\n\n\nlibrary(tidyverse)\nlibrary(DT)\nlibrary(lubridate)\nlibrary(ggthemes)\nlibrary(RColorBrewer)\n\n\n\n\n\nThis example is taken from Kaggle Shelter Outcomes https://www.kaggle.com/c/shelter-animal-outcomes\n\n\nlibrary(readr)\ntrain &lt;- read_csv(\"train.csv.gz\")\n\nA .gz or a .zip is a compressed file. Compression saves space on our machines. The functions in readr can read those directly (some functions require decompression first)\n\nThe dataset train contains the following variables, take a look:\n\n\ndatatable(train)\n\n\n\n\n\n\nmore compactly\n\nglimpse(train)\n\nRows: 26,729\nColumns: 10\n$ AnimalID       &lt;chr&gt; \"A671945\", \"A656520\", \"A686464\", \"A683430\", \"A667013\", …\n$ Name           &lt;chr&gt; \"Hambone\", \"Emily\", \"Pearce\", NA, NA, \"Elsa\", \"Jimmy\", …\n$ DateTime       &lt;dttm&gt; 2014-02-12 18:22:00, 2013-10-13 12:44:00, 2015-01-31 1…\n$ OutcomeType    &lt;chr&gt; \"Return_to_owner\", \"Euthanasia\", \"Adoption\", \"Transfer\"…\n$ OutcomeSubtype &lt;chr&gt; NA, \"Suffering\", \"Foster\", \"Partner\", \"Partner\", \"Partn…\n$ AnimalType     &lt;chr&gt; \"Dog\", \"Cat\", \"Dog\", \"Cat\", \"Dog\", \"Dog\", \"Cat\", \"Cat\",…\n$ SexuponOutcome &lt;chr&gt; \"Neutered Male\", \"Spayed Female\", \"Neutered Male\", \"Int…\n$ AgeuponOutcome &lt;chr&gt; \"1 year\", \"1 year\", \"2 years\", \"3 weeks\", \"2 years\", \"1…\n$ Breed          &lt;chr&gt; \"Shetland Sheepdog Mix\", \"Domestic Shorthair Mix\", \"Pit…\n$ Color          &lt;chr&gt; \"Brown/White\", \"Cream Tabby\", \"Blue/White\", \"Blue Cream…\n\n\n\n\n\n\nThe data needs to be prepared or processed for analysis (data cleaning)\n\nAn important issue will always be missing values.\nna.omit( ) or complete.cases() can be used. (In more advanced courses, substitution of missing values instead of deletion)\n\n\n\n\ntrain %&gt;% summarise_all(funs(sum(is.na(.))))\n\n# A tibble: 1 × 10\n  AnimalID  Name DateTime OutcomeType OutcomeSubtype AnimalType SexuponOutcome\n     &lt;int&gt; &lt;int&gt;    &lt;int&gt;       &lt;int&gt;          &lt;int&gt;      &lt;int&gt;          &lt;int&gt;\n1        0  7691        0           0          13612          0              1\n# ℹ 3 more variables: AgeuponOutcome &lt;int&gt;, Breed &lt;int&gt;, Color &lt;int&gt;\n\n\n\n\n\n\ntrain &lt;- train %&gt;%\n     mutate(NoName = is.na(Name))\n\n\ntable(train$NoName)\n\n\nFALSE  TRUE \n19038  7691 \n\n\nMake some decisions about the remainder. Real life data is always messy so make sure you use the useNA = option when tabling data:\n\ntable(train$OutcomeSubtype, useNA = \"always\")\n\n\n         Aggressive              At Vet                Barn            Behavior \n                320                   4                   2                  86 \nCourt/Investigation             Enroute              Foster           In Foster \n                  6                   8                1800                  52 \n          In Kennel          In Surgery             Medical             Offsite \n                114                   3                  66                 165 \n            Partner         Rabies Risk                SCRP           Suffering \n               7816                  74                1599                1002 \n               &lt;NA&gt; \n              13612 \n\n\n\ntable(train$SexuponOutcome, useNA = \"always\")\n\n\nIntact Female   Intact Male Neutered Male Spayed Female       Unknown \n         3511          3525          9779          8820          1093 \n         &lt;NA&gt; \n            1 \n\n\n\ntable(train$AgeuponOutcome, useNA = \"always\")\n\n\n  0 years     1 day   1 month    1 week   1 weeks    1 year 10 months  10 years \n       22        66      1281       146       171      3969       457       446 \n11 months  11 years  12 years  13 years  14 years  15 years  16 years  17 years \n      166       126       234       143        97        85        36        17 \n 18 years  19 years    2 days  2 months   2 weeks   2 years  20 years    3 days \n       10         3        99      3397       529      3742         2       109 \n 3 months   3 weeks   3 years    4 days  4 months   4 weeks   4 years    5 days \n     1277       659      1823        50       888       334      1071        24 \n 5 months   5 weeks   5 years    6 days  6 months   6 years  7 months   7 years \n      652        11       992        50       588       670       288       531 \n 8 months   8 years  9 months   9 years      &lt;NA&gt; \n      402       536       224       288        18 \n\n\n\ntrain[, c(5,7,8)] &lt;- train %&gt;% select(OutcomeSubtype, SexuponOutcome, AgeuponOutcome) %&gt;%\n     mutate_each(funs(replace(., is.na(.), \"Unknown\")))\n\n\ntrain %&gt;% summarise_all(funs(sum(is.na(.))))\n\n# A tibble: 1 × 11\n  AnimalID  Name DateTime OutcomeType OutcomeSubtype AnimalType SexuponOutcome\n     &lt;int&gt; &lt;int&gt;    &lt;int&gt;       &lt;int&gt;          &lt;int&gt;      &lt;int&gt;          &lt;int&gt;\n1        0  7691        0           0              0          0              0\n# ℹ 4 more variables: AgeuponOutcome &lt;int&gt;, Breed &lt;int&gt;, Color &lt;int&gt;,\n#   NoName &lt;int&gt;\n\n\n\n\n\n\nhead(train$AgeuponOutcome)\n\n[1] \"1 year\"  \"1 year\"  \"2 years\" \"3 weeks\" \"2 years\" \"1 month\"\n\n\n\ntrain$AgeuponOutcome &lt;- gsub('s', '', train$AgeuponOutcome)\n\n\ntable(train$AgeuponOutcome)\n\n\n  0 year    1 day  1 month   1 week   1 year 10 month  10 year 11 month \n      22       66     1281      317     3969      457      446      166 \n 11 year  12 year  13 year  14 year  15 year  16 year  17 year  18 year \n     126      234      143       97       85       36       17       10 \n 19 year    2 day  2 month   2 week   2 year  20 year    3 day  3 month \n       3       99     3397      529     3742        2      109     1277 \n  3 week   3 year    4 day  4 month   4 week   4 year    5 day  5 month \n     659     1823       50      888      334     1071       24      652 \n  5 week   5 year    6 day  6 month   6 year  7 month   7 year  8 month \n      11      992       50      588      670      288      531      402 \n  8 year  9 month   9 year  Unknown \n     536      224      288       18"
  },
  {
    "objectID": "EDA.html#loading-libraries",
    "href": "EDA.html#loading-libraries",
    "title": "EDA",
    "section": "",
    "text": "library(tidyverse)\nlibrary(DT)\nlibrary(lubridate)\nlibrary(ggthemes)\nlibrary(RColorBrewer)"
  },
  {
    "objectID": "EDA.html#case-study",
    "href": "EDA.html#case-study",
    "title": "EDA",
    "section": "",
    "text": "This example is taken from Kaggle Shelter Outcomes https://www.kaggle.com/c/shelter-animal-outcomes\n\n\nlibrary(readr)\ntrain &lt;- read_csv(\"train.csv.gz\")\n\nA .gz or a .zip is a compressed file. Compression saves space on our machines. The functions in readr can read those directly (some functions require decompression first)\n\nThe dataset train contains the following variables, take a look:\n\n\ndatatable(train)\n\n\n\n\n\n\nmore compactly\n\nglimpse(train)\n\nRows: 26,729\nColumns: 10\n$ AnimalID       &lt;chr&gt; \"A671945\", \"A656520\", \"A686464\", \"A683430\", \"A667013\", …\n$ Name           &lt;chr&gt; \"Hambone\", \"Emily\", \"Pearce\", NA, NA, \"Elsa\", \"Jimmy\", …\n$ DateTime       &lt;dttm&gt; 2014-02-12 18:22:00, 2013-10-13 12:44:00, 2015-01-31 1…\n$ OutcomeType    &lt;chr&gt; \"Return_to_owner\", \"Euthanasia\", \"Adoption\", \"Transfer\"…\n$ OutcomeSubtype &lt;chr&gt; NA, \"Suffering\", \"Foster\", \"Partner\", \"Partner\", \"Partn…\n$ AnimalType     &lt;chr&gt; \"Dog\", \"Cat\", \"Dog\", \"Cat\", \"Dog\", \"Dog\", \"Cat\", \"Cat\",…\n$ SexuponOutcome &lt;chr&gt; \"Neutered Male\", \"Spayed Female\", \"Neutered Male\", \"Int…\n$ AgeuponOutcome &lt;chr&gt; \"1 year\", \"1 year\", \"2 years\", \"3 weeks\", \"2 years\", \"1…\n$ Breed          &lt;chr&gt; \"Shetland Sheepdog Mix\", \"Domestic Shorthair Mix\", \"Pit…\n$ Color          &lt;chr&gt; \"Brown/White\", \"Cream Tabby\", \"Blue/White\", \"Blue Cream…"
  },
  {
    "objectID": "EDA.html#initial-steps",
    "href": "EDA.html#initial-steps",
    "title": "EDA",
    "section": "",
    "text": "The data needs to be prepared or processed for analysis (data cleaning)\n\nAn important issue will always be missing values.\nna.omit( ) or complete.cases() can be used. (In more advanced courses, substitution of missing values instead of deletion)\n\n\n\n\ntrain %&gt;% summarise_all(funs(sum(is.na(.))))\n\n# A tibble: 1 × 10\n  AnimalID  Name DateTime OutcomeType OutcomeSubtype AnimalType SexuponOutcome\n     &lt;int&gt; &lt;int&gt;    &lt;int&gt;       &lt;int&gt;          &lt;int&gt;      &lt;int&gt;          &lt;int&gt;\n1        0  7691        0           0          13612          0              1\n# ℹ 3 more variables: AgeuponOutcome &lt;int&gt;, Breed &lt;int&gt;, Color &lt;int&gt;\n\n\n\n\n\n\ntrain &lt;- train %&gt;%\n     mutate(NoName = is.na(Name))\n\n\ntable(train$NoName)\n\n\nFALSE  TRUE \n19038  7691 \n\n\nMake some decisions about the remainder. Real life data is always messy so make sure you use the useNA = option when tabling data:\n\ntable(train$OutcomeSubtype, useNA = \"always\")\n\n\n         Aggressive              At Vet                Barn            Behavior \n                320                   4                   2                  86 \nCourt/Investigation             Enroute              Foster           In Foster \n                  6                   8                1800                  52 \n          In Kennel          In Surgery             Medical             Offsite \n                114                   3                  66                 165 \n            Partner         Rabies Risk                SCRP           Suffering \n               7816                  74                1599                1002 \n               &lt;NA&gt; \n              13612 \n\n\n\ntable(train$SexuponOutcome, useNA = \"always\")\n\n\nIntact Female   Intact Male Neutered Male Spayed Female       Unknown \n         3511          3525          9779          8820          1093 \n         &lt;NA&gt; \n            1 \n\n\n\ntable(train$AgeuponOutcome, useNA = \"always\")\n\n\n  0 years     1 day   1 month    1 week   1 weeks    1 year 10 months  10 years \n       22        66      1281       146       171      3969       457       446 \n11 months  11 years  12 years  13 years  14 years  15 years  16 years  17 years \n      166       126       234       143        97        85        36        17 \n 18 years  19 years    2 days  2 months   2 weeks   2 years  20 years    3 days \n       10         3        99      3397       529      3742         2       109 \n 3 months   3 weeks   3 years    4 days  4 months   4 weeks   4 years    5 days \n     1277       659      1823        50       888       334      1071        24 \n 5 months   5 weeks   5 years    6 days  6 months   6 years  7 months   7 years \n      652        11       992        50       588       670       288       531 \n 8 months   8 years  9 months   9 years      &lt;NA&gt; \n      402       536       224       288        18 \n\n\n\ntrain[, c(5,7,8)] &lt;- train %&gt;% select(OutcomeSubtype, SexuponOutcome, AgeuponOutcome) %&gt;%\n     mutate_each(funs(replace(., is.na(.), \"Unknown\")))\n\n\ntrain %&gt;% summarise_all(funs(sum(is.na(.))))\n\n# A tibble: 1 × 11\n  AnimalID  Name DateTime OutcomeType OutcomeSubtype AnimalType SexuponOutcome\n     &lt;int&gt; &lt;int&gt;    &lt;int&gt;       &lt;int&gt;          &lt;int&gt;      &lt;int&gt;          &lt;int&gt;\n1        0  7691        0           0              0          0              0\n# ℹ 4 more variables: AgeuponOutcome &lt;int&gt;, Breed &lt;int&gt;, Color &lt;int&gt;,\n#   NoName &lt;int&gt;\n\n\n\n\n\n\nhead(train$AgeuponOutcome)\n\n[1] \"1 year\"  \"1 year\"  \"2 years\" \"3 weeks\" \"2 years\" \"1 month\"\n\n\n\ntrain$AgeuponOutcome &lt;- gsub('s', '', train$AgeuponOutcome)\n\n\ntable(train$AgeuponOutcome)\n\n\n  0 year    1 day  1 month   1 week   1 year 10 month  10 year 11 month \n      22       66     1281      317     3969      457      446      166 \n 11 year  12 year  13 year  14 year  15 year  16 year  17 year  18 year \n     126      234      143       97       85       36       17       10 \n 19 year    2 day  2 month   2 week   2 year  20 year    3 day  3 month \n       3       99     3397      529     3742        2      109     1277 \n  3 week   3 year    4 day  4 month   4 week   4 year    5 day  5 month \n     659     1823       50      888      334     1071       24      652 \n  5 week   5 year    6 day  6 month   6 year  7 month   7 year  8 month \n      11      992       50      588      670      288      531      402 \n  8 year  9 month   9 year  Unknown \n     536      224      288       18"
  },
  {
    "objectID": "EDA.html#making-more-of-that-datetime",
    "href": "EDA.html#making-more-of-that-datetime",
    "title": "EDA",
    "section": "Making more of that DateTime",
    "text": "Making more of that DateTime\n\ntrain$hour    &lt;- hour(train$DateTime)\ntrain$DOW &lt;- wday(train$DateTime)\ntrain$month   &lt;- month(train$DateTime)\ntrain$year    &lt;- year(train$DateTime)\n\nConsider squeezing more information out of the data, Time of day can help us figure out when they are open:\n\nplot(table(train$hour), type=\"h\")\n\n\n\n\n\ntrain$period   &lt;- ifelse(train$hour &gt; 8 & train$hour &lt; 11, 'early',\n                  ifelse(train$hour &gt; 10 & train$hour &lt; 17, 'midday',\n                  ifelse(train$hour &gt; 16 & train$hour &lt; 19, 'endday', 'overnight')))\n\nthere is a problem with the ordering\n\nggplot(train, aes(x = period, y = AgeInDays)) + geom_boxplot() + theme_classic()"
  },
  {
    "objectID": "EDA.html#check-the-results",
    "href": "EDA.html#check-the-results",
    "title": "EDA",
    "section": "check the results",
    "text": "check the results\n\nggplot(train, aes(x = period, y = AgeInDays)) + \n    geom_boxplot(fill=c(\"red\", \"orange\",\"yellow\", \"green\")) + \n    theme_classic()"
  },
  {
    "objectID": "EDA.html#always-always-check-the-data",
    "href": "EDA.html#always-always-check-the-data",
    "title": "EDA",
    "section": "Always, Always Check The Data",
    "text": "Always, Always Check The Data\nYou should probably run a quick summary or some other function which generates ranges and tabulates NAs to make certain that there are no unusual observations\n\nsummary(train)\n\n   AnimalID             Name              DateTime                     \n Length:26729       Length:26729       Min.   :2013-10-01 09:31:00.00  \n Class :character   Class :character   1st Qu.:2014-05-31 16:31:00.00  \n Mode  :character   Mode  :character   Median :2014-12-13 17:10:00.00  \n                                       Mean   :2014-12-19 00:22:23.96  \n                                       3rd Qu.:2015-07-19 19:48:00.00  \n                                       Max.   :2016-02-21 19:17:00.00  \n                                                                       \n OutcomeType        OutcomeSubtype      AnimalType        SexuponOutcome    \n Length:26729       Length:26729       Length:26729       Length:26729      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n AgeuponOutcome        Breed              Color             NoName       \n Length:26729       Length:26729       Length:26729       Mode :logical  \n Class :character   Class :character   Class :character   FALSE:19038    \n Mode  :character   Mode  :character   Mode  :character   TRUE :7691     \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n      Age             Unit             AgeInDays           hour      \n Min.   : 0.000   Length:26729       Min.   :   0.0   Min.   : 0.00  \n 1st Qu.: 2.000   Class :character   1st Qu.:  60.0   1st Qu.:12.00  \n Median : 2.000   Mode  :character   Median : 365.0   Median :15.00  \n Mean   : 3.628                      Mean   : 794.1   Mean   :14.45  \n 3rd Qu.: 5.000                      3rd Qu.:1095.0   3rd Qu.:17.00  \n Max.   :20.000                      Max.   :7300.0   Max.   :23.00  \n NA's   :18                          NA's   :18                      \n      DOW            month             year            period     \n Min.   :1.000   Min.   : 1.000   Min.   :2013   early    : 1683  \n 1st Qu.:2.000   1st Qu.: 4.000   1st Qu.:2014   midday   :15195  \n Median :4.000   Median : 7.000   Median :2014   endday   : 7846  \n Mean   :3.976   Mean   : 6.926   Mean   :2014   overnight: 2005  \n 3rd Qu.:6.000   3rd Qu.:10.000   3rd Qu.:2015                    \n Max.   :7.000   Max.   :12.000   Max.   :2016                    \n                                                                  \n\n\nconsider building a dplyr solution\n\nlibrary(dplyr)\nlibrary(tidyr)\ntrain %&gt;% select(14:18) %&gt;% \n            summarise_each(funs(min = min(., na.rm = TRUE), \n                      q25 = quantile(.,probs = 0.25, na.rm = TRUE), \n                      median = median(.,na.rm = TRUE), \n                      q75 = quantile(.,probs = 0.75, na.rm = TRUE), \n                      max = max(.,na.rm = TRUE),\n                      mean = mean(.,na.rm = TRUE), \n                      sd = sd(.,na.rm = TRUE)))  %&gt;%\ngather(stat, val) %&gt;%\nseparate(stat, into = c(\"var\", \"stat\"), sep = \"_\") %&gt;%\nspread(stat, val) %&gt;%\nselect(var, min, q25, median, q75, max, mean, sd) # reorder columns\n\n# A tibble: 5 × 8\n  var         min   q25 median   q75   max    mean       sd\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 AgeInDays     0    60    365  1095  7300  794.   1083.   \n2 DOW           1     2      4     6     7    3.98    2.07 \n3 hour          0    12     15    17    23   14.4     3.34 \n4 month         1     4      7    10    12    6.93    3.50 \n5 year       2013  2014   2014  2015  2016 2014.      0.741"
  },
  {
    "objectID": "EDA.html#variables-of-substance",
    "href": "EDA.html#variables-of-substance",
    "title": "EDA",
    "section": "Variables of Substance",
    "text": "Variables of Substance\nKnowing the number of unique values can help us determine whether a variable is suitable for analysis. Sometimes, a variable with many unique values is really just an identifier that is more useful for joining (merging) than for analysis. An example would be student id number, social security numbers, cell phone number etc.\nYou can use functions such as unique() to find out how many unique values a given variable has:\n\nsapply(train, function(x) length(unique(x)))\n\n      AnimalID           Name       DateTime    OutcomeType OutcomeSubtype \n         26729           6373          22918              5             17 \n    AnimalType SexuponOutcome AgeuponOutcome          Breed          Color \n             2              5             44           1380            366 \n        NoName            Age           Unit      AgeInDays           hour \n             2             22              5             44             20 \n           DOW          month           year         period \n             7             12              4              4 \n\n\n\ntrain %&gt;% summarise_all(funs(n_distinct(.)))\n\n# A tibble: 1 × 19\n  AnimalID  Name DateTime OutcomeType OutcomeSubtype AnimalType SexuponOutcome\n     &lt;int&gt; &lt;int&gt;    &lt;int&gt;       &lt;int&gt;          &lt;int&gt;      &lt;int&gt;          &lt;int&gt;\n1    26729  6373    22918           5             17          2              5\n# ℹ 12 more variables: AgeuponOutcome &lt;int&gt;, Breed &lt;int&gt;, Color &lt;int&gt;,\n#   NoName &lt;int&gt;, Age &lt;int&gt;, Unit &lt;int&gt;, AgeInDays &lt;int&gt;, hour &lt;int&gt;,\n#   DOW &lt;int&gt;, month &lt;int&gt;, year &lt;int&gt;, period &lt;int&gt;\n\n\ntidyr is useful for this kind of aggressive data restructuring\n\ntrain %&gt;%\n  gather(var, value) %&gt;% \n  distinct() %&gt;% \n  count(var)\n\n# A tibble: 19 × 2\n   var                n\n   &lt;chr&gt;          &lt;int&gt;\n 1 Age               22\n 2 AgeInDays         44\n 3 AgeuponOutcome    44\n 4 AnimalID       26729\n 5 AnimalType         2\n 6 Breed           1380\n 7 Color            366\n 8 DOW                7\n 9 DateTime       22918\n10 Name            6373\n11 NoName             2\n12 OutcomeSubtype    17\n13 OutcomeType        5\n14 SexuponOutcome     5\n15 Unit               5\n16 hour              20\n17 month             12\n18 period             4\n19 year               4\n\n\nVariables with few values can serve as grouping variables (good variables to use for subsetting)."
  },
  {
    "objectID": "EDA.html#string-work",
    "href": "EDA.html#string-work",
    "title": "EDA",
    "section": "String work",
    "text": "String work\nThe variables that typically have too many values are strings, but we can be creative. There are 366 colors, too many to view on screen, but we can table and save to a data frame:\n\ncolors &lt;- train %&gt;% count(Color)\ndatatable(colors)\n\n\n\n\n\n\n\ncolors &lt;- colors %&gt;% mutate(color_rank = dense_rank(desc(n)))\ndatatable(colors)\n\n\n\n\n\n\n\ntrain2 &lt;- inner_join(train, colors[, c(1,3)])\n\n\nbreed\nThere is a lot of information here, but we can work with it using string functions.\n\ntrain2$mix &lt;- train2$Breed %&gt;% str_detect(., \"/|Mix\") \ndatatable(train2[, c(\"Breed\",\"mix\")])\n\n\n\n\n\n\nYou could probably think of more things we could do with our variables, like popular names, breed information, etc.\n\nWe begin with graphical tools to generate basic plots of the data to illuminate patterns\n\nWe then move into more complex plots to search for deviations from these patterns"
  },
  {
    "objectID": "EDA.html#variation",
    "href": "EDA.html#variation",
    "title": "EDA",
    "section": "Variation",
    "text": "Variation\n\nVariability is interesting and typically one will examine variables with the most variation.\nThere is variability in balance\nWhat is the source(s) of this variation?\n\nOne of the most important things to remember is the type of variable – do I have a numerical or categorical and if I have a numerical – is it discrete or continuous?\n\nggplot(train2, aes(x=AgeInDays)) + \n    geom_histogram(aes(y=..density..),bins=20, fill=\"cyan\", color=\"black\") +\n    ggtitle(\"Age distribution of shelter animals at outcome\") + \n    theme_wsj()\n\n\n\n\n\nggplot(train2, aes(x=AgeInDays)) + \n    geom_histogram(aes(y=..density..),bins=20, fill=\"cyan\", color=\"black\") +\n    facet_wrap(~OutcomeType) +\n    ggtitle(\"Age distribution of shelter animals at outcome\") + \n    theme_tufte()\n\n\n\n\n\nggplot(train2, aes(x=AgeInDays,fill=factor(AnimalType))) + \n    geom_histogram(aes(y=..density..)) +\n    facet_wrap(~OutcomeType + AnimalType) +\n    ggtitle(\"Age distribution of shelter animals at outcome\") + \n    theme_solarized() + theme(legend.position=\"none\")\n\n\n\n\n\nggplot(train2, aes(x=AgeInDays,fill=factor(AnimalType))) + \n    geom_histogram(aes(y=..density..), color = \"black\") +\n    facet_wrap(OutcomeType ~ AnimalType, nrow=5) +\n    ggtitle(\"Age distribution of shelter animals at outcome\") + \n    theme_pander() + theme(legend.position=\"none\")"
  },
  {
    "objectID": "EDA.html#outliers-or-unusual-values",
    "href": "EDA.html#outliers-or-unusual-values",
    "title": "EDA",
    "section": "Outliers or Unusual Values",
    "text": "Outliers or Unusual Values\nWe might transform the variable “AgeInDays” to help us better understand it or perhaps make it more presentable.\nUsually long right hand tails can use a square root or a log transformation to help normalize them or at least bring the relationship into clearer focus:\n\ntrain2$AO &lt;- paste(train2$AnimalType, train2$OutcomeType, sep=\"-\")\nggplot(train2, aes(x=AO, y=sqrt(AgeInDays))) + \n    geom_boxplot(fill=rep(c(\"red\",\"blue\"), each=5)) + \n    theme(axis.text.x = element_text(angle = 90, hjust = 1)) \n\n\n\n\nSo perhaps outliers are a combination of age, animal type and outcome. Old cats are not usually adopted (and old for a cat is about 2 years) and a dog is not “old” unil 6 or 7 years of age."
  },
  {
    "objectID": "EDA.html#working-with-groups",
    "href": "EDA.html#working-with-groups",
    "title": "EDA",
    "section": "Working with groups",
    "text": "Working with groups\nTables are a start when working with categorical (non-numeric) variables\n\ntable(train2$OutcomeType, train2$SexuponOutcome, train2$AnimalType)\n\n, ,  = Cat\n\n                 \n                  Intact Female Intact Male Neutered Male Spayed Female Unknown\n  Adoption                  141          97          2001          2033       0\n  Died                       40          64             9            11      23\n  Euthanasia                206         231           108            75      90\n  Return_to_owner            18          10           252           213       7\n  Transfer                 1709        1525           695           680     896\n\n, ,  = Dog\n\n                 \n                  Intact Female Intact Male Neutered Male Spayed Female Unknown\n  Adoption                   62          61          3221          3153       0\n  Died                       16          15            10             7       2\n  Euthanasia                195         246           236           157      11\n  Return_to_owner           283         467          1995          1535       6\n  Transfer                  841         809          1252           956      59\n\n\n\nprop.table(table(train2$OutcomeType, train2$SexuponOutcome, train2$AnimalType),c(1,3))\n\n, ,  = Cat\n\n                 \n                  Intact Female Intact Male Neutered Male Spayed Female\n  Adoption          0.033005618 0.022705993   0.468398876   0.475889513\n  Died              0.272108844 0.435374150   0.061224490   0.074829932\n  Euthanasia        0.290140845 0.325352113   0.152112676   0.105633803\n  Return_to_owner   0.036000000 0.020000000   0.504000000   0.426000000\n  Transfer          0.310445050 0.277020890   0.126248865   0.123524069\n                 \n                      Unknown\n  Adoption        0.000000000\n  Died            0.156462585\n  Euthanasia      0.126760563\n  Return_to_owner 0.014000000\n  Transfer        0.162761126\n\n, ,  = Dog\n\n                 \n                  Intact Female Intact Male Neutered Male Spayed Female\n  Adoption          0.009542866 0.009388949   0.495767277   0.485300908\n  Died              0.320000000 0.300000000   0.200000000   0.140000000\n  Euthanasia        0.230769231 0.291124260   0.279289941   0.185798817\n  Return_to_owner   0.066028931 0.108959403   0.465468969   0.358142790\n  Transfer          0.214705131 0.206535614   0.319632372   0.244064335\n                 \n                      Unknown\n  Adoption        0.000000000\n  Died            0.040000000\n  Euthanasia      0.013017751\n  Return_to_owner 0.001399907\n  Transfer        0.015062548\n\n\n\ntable(train2$OutcomeType, train2$SexuponOutcome, train2$AnimalType) %&gt;% \n    prop.table(c(2,3)) %&gt;%\n    round(3)\n\n, ,  = Cat\n\n                 \n                  Intact Female Intact Male Neutered Male Spayed Female Unknown\n  Adoption                0.067       0.050         0.653         0.675   0.000\n  Died                    0.019       0.033         0.003         0.004   0.023\n  Euthanasia              0.097       0.120         0.035         0.025   0.089\n  Return_to_owner         0.009       0.005         0.082         0.071   0.007\n  Transfer                0.808       0.791         0.227         0.226   0.882\n\n, ,  = Dog\n\n                 \n                  Intact Female Intact Male Neutered Male Spayed Female Unknown\n  Adoption                0.044       0.038         0.480         0.543   0.000\n  Died                    0.011       0.009         0.001         0.001   0.026\n  Euthanasia              0.140       0.154         0.035         0.027   0.141\n  Return_to_owner         0.203       0.292         0.297         0.264   0.077\n  Transfer                0.602       0.506         0.186         0.165   0.756"
  },
  {
    "objectID": "EDA.html#heat-map",
    "href": "EDA.html#heat-map",
    "title": "EDA",
    "section": "heat map",
    "text": "heat map\n\nmy_palette &lt;- brewer.pal(n = 11, name = \"Spectral\")\n\n train2 %&gt;%\n      count(AO, period) %&gt;%\n      ggplot(mapping = aes(x = AO, y = period)) +\n        geom_tile(mapping = aes(fill = n), alpha = 0.75) +\n        scale_fill_gradientn(colors = my_palette)  +\n        labs(x = \"Animal Outcome\", y = \"Time Period\", title = \"Animal Outcomes by time period\") +\n        theme(axis.text.x = element_text(angle = 90, hjust = 1))"
  },
  {
    "objectID": "EffectSize.html",
    "href": "EffectSize.html",
    "title": "Effect Size",
    "section": "",
    "text": "Please enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn case the contour map does not render:\n\n\n\ncontour\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLooks like there are two managers tied at the top (14 + 21) followed by 23 and then 2."
  },
  {
    "objectID": "Normals.html",
    "href": "Normals.html",
    "title": "Normal Distributions",
    "section": "",
    "text": "Please enable JavaScript to experience the dynamic code cell content on this page.\nR has built in datasets, one of them is named trees. We can examine the first few rows.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe see that there are three characteristics measured for each tree in the dataset: Girth Height Volume\nA histogram is a way to represent and reorganize data as a single image:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nhist() is a function, trees$Height can be read as “trees extract Height”, we will color it green and label the graphic.\nIt looks normal-like to our eyes, but we can confirm it with a Shapiro-Wilk test:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nshapiro.test() is the name of the function and it takes a single argument, what data do we want to test (e.g., the height information from the dataset trees). It appears to be normal since the p-value &gt; 0.05 (not too different from normal)\nWe can follow this with a Rosner test (since n &gt; 25)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThere do not appear to be any outliers.\nLet’s look at a different characteristic of trees, their Volume. This is a different and more complex plotting function:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis one does not look as normal as Height. The Shapiro.test confirms it.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe will guess that a log transformation might fix it. The log transformation will result in the more extreme values getting pulled towards the left:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe Shapiro-Wilks test confirms what we are seeing.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nA different tool to help understand normality, a q-q plot, has two components qqnorm() which converts the values of our data to quantiles of a normal distribution (points that mark where a certain percentage of the data values fall below them) followed by qqline() which draws a representation of the points from a truly normal distribution for comparison.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe deviations away from the red line give us an idea of how far the distribution departs from normal. Compare with the untransformed original:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can see that the transformation was helpful by normalizing the distribution.\nLet’s test for outliers.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNo outliers.\nYour turn! We have a dataset named “penguins” consisting of three different species: Adelie, Chinstrap and Gentoo. We should probably separate them out and check for normality separately.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nChoose a numeric variable like bill_length_mm\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nTry some tests or some graphs or both! You can type in the box below and then press run code. Do any of the penguin groups have any outliers?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "To learn more about Quarto websites please visit https://quarto.org/docs/websites.\nTo learn more about WebR please visit https://quarto-webr.thecoatlessprofessor.com/qwebr-first-steps.html.\nAnd this site is hosted by GitHub (free) and easy setup and maintenance https://pages.github.com/\nThat is not a photograph of me, but my family’s cat, Harry. That was taken Christmas morning after I asked him to get out of my chair."
  },
  {
    "objectID": "SROI.html#introduction",
    "href": "SROI.html#introduction",
    "title": "SROI",
    "section": "Introduction",
    "text": "Introduction\n\nSocial Return on Investment (SROI) analysis is a way to measure and document the value created by social, environmental, and economic activities.\nSROI is an approach that can help organizations understand the influence of their work on stakeholders above and beyond standard financial metrics.\nSROI goal is to generate a more comprehensive view of the performance and effectiveness of an organization or project by monetarily valuing social and environmental outcomes,"
  },
  {
    "objectID": "SROI.html#sroi-analysis",
    "href": "SROI.html#sroi-analysis",
    "title": "SROI",
    "section": "SROI analysis",
    "text": "SROI analysis\ninvolves:\n\nIdentifying Stakeholders: Determining who is affected by the organization’s activities and should be part of the analysis.\nMapping Outcomes: Identifying the social, environmental, and economic outcomes resulting from the organization’s activities.\nEvidencing Outcomes: Collecting evidence for the outcomes\nValuing Outcomes: estimating the value of outcomes monetarily"
  },
  {
    "objectID": "SROI.html#sroi-analysis-1",
    "href": "SROI.html#sroi-analysis-1",
    "title": "SROI",
    "section": "SROI Analysis:",
    "text": "SROI Analysis:\n\nEstablishing Impact: Understanding and articulating how much of the outcome was caused by the organization’s activities which means:\n\nIdentifying what would have happened anyway\nAcknowledging the contribution of other factors\nReplacing one outcome with another\nRecognizing how outcomes change over time\n\nCalculating SROI: Sum the benefits, deduct the negatives, and comparing the result to the investment.\nReport and Apply: Communicating the findings from the SROI analysis and using them to make decisions and improve performance."
  },
  {
    "objectID": "SROI.html#sroi-analysis-contd",
    "href": "SROI.html#sroi-analysis-contd",
    "title": "SROI",
    "section": "SROI Analysis (cont’d):",
    "text": "SROI Analysis (cont’d):\n\nEstablishing Impact: Understanding and articulating how much of the outcome was caused by the organization’s activities which means:\n\nIdentifying what would have happened anyway\nAcknowledging the contribution of other factors\nReplacing one outcome with another\nRecognizing how outcomes change over time"
  },
  {
    "objectID": "SROI.html#sroi-analysis-contd-1",
    "href": "SROI.html#sroi-analysis-contd-1",
    "title": "SROI",
    "section": "SROI Analysis (cont’d):",
    "text": "SROI Analysis (cont’d):\n\nCalculating SROI: Sum the benefits, deduct the negatives, and comparing the result to the investment.\nReport and Apply: Communicating the findings from the SROI analysis and using them to make decisions and improve performance."
  },
  {
    "objectID": "SROI.html#technical-background",
    "href": "SROI.html#technical-background",
    "title": "SROI",
    "section": "Technical Background:",
    "text": "Technical Background:\nThe level of mathematics or statistics required for Social Return on Investment (SROI) analysis varies with the depth and complexity of the analysis.\n\nBasic Arithmetic: Comfort with basic arithmetic operations (addition, subtraction, multiplication, division)\nAlgebra: Understanding how to solve equations and manipulate algebraic expressions\nPercentages and Proportions Understanding how to calculate and interpret percentages"
  },
  {
    "objectID": "SROI.html#technical-background-1",
    "href": "SROI.html#technical-background-1",
    "title": "SROI",
    "section": "Technical Background",
    "text": "Technical Background\n\nDiscounting: The concept of discounting future benefits and costs to their present value is important in SROI analysis. This requires an understanding of the time value of money and how to apply discount rates to future cash flows.\nNet Present Value (NPV): Calculating the NPV involves understanding how to sum present values of future benefits and costs, taking into account the investment made."
  },
  {
    "objectID": "SROI.html#technical-background-2",
    "href": "SROI.html#technical-background-2",
    "title": "SROI",
    "section": "Technical Background",
    "text": "Technical Background\n\nDescriptive Statistics: Basic understanding of means, medians, modes, ranges, and standard deviation can help in analyzing and summarizing data.\nInferential Statistics: Knowledge of statistical significance, confidence intervals, and hypothesis testing can be useful for attributing outcomes to interventions and for understanding the uncertainty in your estimates.\nSensitivity Analysis for assessing how changes in key assumptions or variables affect the outcomes. This involves varying inputs to understand how the results change."
  },
  {
    "objectID": "SROI.html#technical-background-contd",
    "href": "SROI.html#technical-background-contd",
    "title": "SROI",
    "section": "Technical Background (cont’d):",
    "text": "Technical Background (cont’d):\n\nDiscounting: The concept of discounting future benefits and costs to their present value is important in SROI analysis. This requires an understanding of the time value of money and how to apply discount rates to future cash flows.\nNet Present Value (NPV): Calculating the NPV involves understanding how to sum present values of future benefits and costs, taking into account the investment made."
  },
  {
    "objectID": "SROI.html#technical-background-contd-1",
    "href": "SROI.html#technical-background-contd-1",
    "title": "SROI",
    "section": "Technical Background (cont’d):",
    "text": "Technical Background (cont’d):\n\nDescriptive Statistics: Basic understanding of means, medians, modes, ranges, and standard deviation can help in analyzing and summarizing data.\nInferential Statistics: Knowledge of statistical significance, confidence intervals, and hypothesis testing can be useful for attributing outcomes to interventions and for understanding the uncertainty in your estimates.\nSensitivity Analysis for assessing how changes in key assumptions or variables affect the outcomes. This involves varying inputs to understand how the results change."
  },
  {
    "objectID": "SROI.html#example",
    "href": "SROI.html#example",
    "title": "SROI",
    "section": "Example",
    "text": "Example\nThis was derived from Kennedy & Philips (2011) on using the SROI methodology to evaluate the social impact of an Expert Patient Program for Substance and Alcohol Misuse in a UK region. First their model is described:"
  },
  {
    "objectID": "SROI.html#example-1",
    "href": "SROI.html#example-1",
    "title": "SROI",
    "section": "Example",
    "text": "Example\nThe outcomes are measured\n\nThe total value of each change, was calculated as: - The financial proxy - Multiplied by the reported quantity of the outcome - Minus any deadweight, attribution and / or displacement factors\nThe total is then the total of all the impact calculations for each outcome. The total impact (at the end of the period of analysis)"
  },
  {
    "objectID": "SROI.html#section",
    "href": "SROI.html#section",
    "title": "SROI",
    "section": "",
    "text": "Introduction\n\nSocial Return on Investment (SROI) analysis is a way to measure and document the value created by social, environmental, and economic activities.\nSROI is an approach that can help organizations understand the influence of their work on stakeholders above and beyond standard financial metrics.\nSROI goal is to generate a more comprehensive view of the performance and effectiveness of an organization or project by monetarily valuing social and environmental outcomes,"
  },
  {
    "objectID": "SROI.html#section-1",
    "href": "SROI.html#section-1",
    "title": "SROI",
    "section": "",
    "text": "SROI analysis\ninvolves:\n\nIdentifying Stakeholders: Determining who is affected by the organization’s activities and should be part of the analysis.\nMapping Outcomes: Identifying the social, environmental, and economic outcomes resulting from the organization’s activities.\nEvidencing Outcomes: Collecting evidence for the outcomes\nValuing Outcomes: estimating the value of outcomes monetarily"
  },
  {
    "objectID": "SROI.html#section-2",
    "href": "SROI.html#section-2",
    "title": "SROI",
    "section": "",
    "text": "SROI Analysis (cont’d):\n\nEstablishing Impact: Understanding and articulating how much of the outcome was caused by the organization’s activities which means:\n\nIdentifying what would have happened anyway\nAcknowledging the contribution of other factors\nReplacing one outcome with another\nRecognizing how outcomes change over time"
  },
  {
    "objectID": "SROI.html#section-3",
    "href": "SROI.html#section-3",
    "title": "SROI",
    "section": "",
    "text": "SROI Analysis (cont’d):\n\nCalculating SROI: Sum the benefits, deduct the negatives, and comparing the result to the investment.\nReport and Apply: Communicating the findings from the SROI analysis and using them to make decisions and improve performance."
  },
  {
    "objectID": "SROI.html#section-4",
    "href": "SROI.html#section-4",
    "title": "SROI",
    "section": "",
    "text": "Technical Background:\nThe level of mathematics or statistics required for Social Return on Investment (SROI) analysis varies with the depth and complexity of the analysis.\n\nBasic Arithmetic: Comfort with basic arithmetic operations (addition, subtraction, multiplication, division)\nAlgebra: Understanding how to solve equations and manipulate algebraic expressions\nPercentages and Proportions Understanding how to calculate and interpret percentages"
  },
  {
    "objectID": "SROI.html#section-5",
    "href": "SROI.html#section-5",
    "title": "SROI",
    "section": "",
    "text": "Technical Background (cont’d):\n\nDiscounting: The concept of discounting future benefits and costs to their present value is important in SROI analysis. This requires an understanding of the time value of money and how to apply discount rates to future cash flows.\nNet Present Value (NPV): Calculating the NPV involves understanding how to sum present values of future benefits and costs, taking into account the investment made."
  },
  {
    "objectID": "SROI.html#section-6",
    "href": "SROI.html#section-6",
    "title": "SROI",
    "section": "",
    "text": "Technical Background (cont’d):\n\nDescriptive Statistics: Basic understanding of means, medians, modes, ranges, and standard deviation can help in analyzing and summarizing data.\nInferential Statistics: Knowledge of statistical significance, confidence intervals, and hypothesis testing can be useful for attributing outcomes to interventions and for understanding the uncertainty in your estimates.\nSensitivity Analysis for assessing how changes in key assumptions or variables affect the outcomes. This involves varying inputs to understand how the results change."
  },
  {
    "objectID": "SROI.html#section-7",
    "href": "SROI.html#section-7",
    "title": "SROI",
    "section": "",
    "text": "Example\nThis was derived from Kennedy & Philips (2011) on using the SROI methodology to evaluate the social impact of an Expert Patient Program for Substance and Alcohol Misuse in a UK region. First their model is described in the next slide"
  },
  {
    "objectID": "SROI.html#section-8",
    "href": "SROI.html#section-8",
    "title": "SROI",
    "section": "",
    "text": "Example\nThen the outcomes are measured"
  },
  {
    "objectID": "SROI.html#model",
    "href": "SROI.html#model",
    "title": "SROI",
    "section": "Model",
    "text": "Model"
  },
  {
    "objectID": "SROI.html#section-9",
    "href": "SROI.html#section-9",
    "title": "SROI",
    "section": "",
    "text": "Example\nThe total value of each change, was calculated as:\n\nThe financial proxy\n\nMultiplied by the reported quantity of the outcome\n\nMinus any deadweight, attribution and / or displacement factors\n\nThe total is then the total of all the impact calculations for each outcome. The total impact (at the end of the period of analysis)"
  }
]